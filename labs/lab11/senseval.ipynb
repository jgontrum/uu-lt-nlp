{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wsd_code as wc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore instances and word meanings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'hard' appears 4333 times\n",
      "The word has 3 different meanings.\n",
      "SensevalInstance(word='hard-a', position=20, context=[('``', '``'), ('he', 'PRP'), ('may', 'MD'), ('lose', 'VB'), ('all', 'DT'), ('popular', 'JJ'), ('support', 'NN'), (',', ','), ('but', 'CC'), ('someone', 'NN'), ('has', 'VBZ'), ('to', 'TO'), ('kill', 'VB'), ('him', 'PRP'), ('to', 'TO'), ('defeat', 'VB'), ('him', 'PRP'), ('and', 'CC'), ('that', 'DT'), (\"'s\", 'VBZ'), ('hard', 'JJ'), ('to', 'TO'), ('do', 'VB'), ('.', '.'), (\"''\", \"''\")], senses=('HARD1',))\n",
      "SensevalInstance(word='hard-a', position=10, context=[('clever', 'NNP'), ('white', 'NNP'), ('house', 'NNP'), ('``', '``'), ('spin', 'VB'), ('doctors', 'NNS'), (\"''\", \"''\"), ('are', 'VBP'), ('having', 'VBG'), ('a', 'DT'), ('hard', 'JJ'), ('time', 'NN'), ('helping', 'VBG'), ('president', 'NNP'), ('bush', 'NNP'), ('explain', 'VB'), ('away', 'RB'), ('the', 'DT'), ('economic', 'JJ'), ('bashing', 'NN'), ('that', 'IN'), ('low-and', 'JJ'), ('middle-income', 'JJ'), ('workers', 'NNS'), ('are', 'VBP'), ('taking', 'VBG'), ('these', 'DT'), ('days', 'NNS'), ('.', '.')], senses=('HARD1',))\n",
      "\n",
      "'interest' appears 2368 times\n",
      "The word has 6 different meanings.\n",
      "SensevalInstance(word='interest-n', position=18, context=[('yields', 'NNS'), ('on', 'IN'), ('money-market', 'JJ'), ('mutual', 'JJ'), ('funds', 'NNS'), ('continued', 'VBD'), ('to', 'TO'), ('slide', 'VB'), (',', ','), ('amid', 'IN'), ('signs', 'VBZ'), ('that', 'IN'), ('portfolio', 'NN'), ('managers', 'NNS'), ('expect', 'VBP'), ('further', 'JJ'), ('declines', 'NNS'), ('in', 'IN'), ('interest', 'NN'), ('rates', 'NNS'), ('.', '.')], senses=('interest_6',))\n",
      "SensevalInstance(word='interest-n', position=7, context=[('longer', 'RB'), ('maturities', 'NNS'), ('are', 'VBP'), ('thought', 'VBN'), ('to', 'TO'), ('indicate', 'VB'), ('declining', 'VBG'), ('interest', 'NN'), ('rates', 'NNS'), ('because', 'IN'), ('they', 'PRP'), ('permit', 'VBP'), ('portfolio', 'NN'), ('managers', 'NNS'), ('to', 'TO'), ('retain', 'VB'), ('relatively', 'RB'), ('higher', 'JJR'), ('rates', 'NNS'), ('for', 'IN'), ('a', 'DT'), ('longer', 'RB'), ('period', 'NN'), ('.', '.')], senses=('interest_6',))\n",
      "\n",
      "'serve' appears 4378 times\n",
      "The word has 4 different meanings.\n",
      "SensevalInstance(word='serve-v', position=42, context=[('some', 'DT'), ('tart', 'JJ'), ('fruits', 'NNS'), ('mixed', 'VBN'), ('with', 'IN'), ('greens', 'NNS'), ('make', 'VBP'), ('a', 'DT'), ('nice', 'JJ'), ('contrast', 'NN'), ('with', 'IN'), ('rich', 'JJ'), ('meat', 'NN'), ('dishes', 'NNS'), ('(', '('), ('see', 'VB'), ('orange', 'NNP'), ('and', 'CC'), ('onion', 'NNP'), ('salad', 'NNP'), (',', ','), ('page', 'NN'), ('111', 'CD'), (')', 'SYM'), (',', ','), ('but', 'CC'), ('if', 'IN'), ('you', 'PRP'), ('like', 'VB'), ('to', 'TO'), ('follow', 'VB'), ('the', 'DT'), ('meat', 'NN'), ('course', 'NN'), ('with', 'IN'), ('sweet', 'JJ'), ('fruit', 'NN'), (',', ','), ('it', 'PRP'), ('seems', 'VBZ'), ('wiser', 'JJR'), ('to', 'TO'), ('serve', 'VB'), ('it', 'PRP'), ('plain', 'JJ'), ('with', 'IN'), ('a', 'DT'), ('good', 'JJ'), ('sharp', 'JJ'), ('cheese', 'NN'), ('and', 'CC'), ('let', 'VB'), ('it', 'PRP'), ('take', 'VB'), ('the', 'DT'), ('place', 'NN'), ('of', 'IN'), ('a', 'DT'), ('sweet', 'JJ'), ('or', 'CC'), ('dessert', 'NN'), ('course', 'NN'), ('.', '.'), ('if', 'IN'), ('you', 'PRP'), ('insist', 'VBP'), ('on', 'IN'), ('serving', 'VBG'), ('fruit', 'NN'), ('as', 'IN'), ('a', 'DT'), ('salad', 'NN'), (',', ','), ('don', 'VB'), (\"'t\", 'NN'), ('cut', 'NN'), ('it', 'PRP'), ('into', 'IN'), ('cubes', 'NNS'), ('and', 'CC'), ('mix', 'NN'), ('it', 'PRP'), ('up', 'RB'), ('.', '.')], senses=('SERVE10',))\n",
      "SensevalInstance(word='serve-v', position=25, context=[('to', 'TO'), ('increase', 'VB'), ('amount', 'NN'), ('of', 'IN'), ('stuffing', 'VBG'), (',', ','), ('preserve', 'VB'), ('ratio', 'NN'), ('of', 'IN'), ('half', 'NN'), ('as', 'IN'), ('much', 'JJ'), ('mushrooms', 'NNS'), ('as', 'IN'), ('bread', 'NN'), ('.', '.'), ('capon', 'NNP'), ('stuffed', 'VBD'), ('in', 'IN'), ('this', 'DT'), ('manner', 'NN'), ('would', 'MD'), ('most', 'RBS'), ('likely', 'JJ'), ('be', 'VB'), ('served', 'VBD'), ('with', 'IN'), ('pan-fried', 'JJ'), ('potatoes', 'NNS'), (',', ','), ('broccoli', 'NNS'), (',', ','), ('or', 'CC'), ('cauliflower', 'NN'), ('browned', 'VBN'), ('in', 'IN'), ('oil', 'NN'), ('.', '.')], senses=('SERVE10',))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def show_instance(word):\n",
    "    # All instances in the corpus containing the given word\n",
    "    instances = wc.senseval.instances('{}.pos'.format(word))\n",
    "    \n",
    "    print(\"'{}' appears {} times\".format(word, len(instances)))\n",
    "    print(\"The word has {} different meanings.\".format(\n",
    "        len(wc.senses('{}.pos'.format(word)))))\n",
    "\n",
    "    # Show the context andd infor of the first context\n",
    "    print(instances[0])\n",
    "    print(instances[1])\n",
    "    print()\n",
    "    \n",
    "for w in \"hard interest serve\".split():\n",
    "    show_instance(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the **random baseline** for the words 'hard' and 'interest'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random baseline for hard: 0.3333333333333333\n",
      "Random interest for interest: 0.16666666666666666\n",
      "Random interest for serve: 0.25\n"
     ]
    }
   ],
   "source": [
    "hard_bl = 1.0 / len(wc.senses('hard.pos'))\n",
    "interest_bl = 1.0 / len(wc.senses('interest.pos'))\n",
    "serve_bl = 1.0 / len(wc.senses('serve.pos'))\n",
    "\n",
    "print(\"Random baseline for hard: %s\" % hard_bl)\n",
    "print(\"Random interest for interest: %s\" % interest_bl)\n",
    "print(\"Random interest for serve: %s\" % serve_bl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **majority baseline** is the accuracy we get, if we always guess the most frequent sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority baseline for 'hard': 0.797369028386799\n",
      "Majority baseline for 'interest': 0.5287162162162162\n",
      "Majority baseline for 'serve': 0.4143444495203289\n"
     ]
    }
   ],
   "source": [
    "def get_majority_baseline(word):\n",
    "    dist = nltk.FreqDist([\n",
    "        i.senses[0] for i in wc.senseval.instances('%s.pos' % word)\n",
    "    ])\n",
    "    most_frequent_sense = max(dist.keys(), key=(lambda k: dist[k]))\n",
    "    \n",
    "    return dist.freq(most_frequent_sense)\n",
    "    \n",
    "print(\"Majority baseline for 'hard': %s\" % get_majority_baseline(\"hard\"))\n",
    "print(\"Majority baseline for 'interest': %s\" % get_majority_baseline(\"interest\"))\n",
    "print(\"Majority baseline for 'serve': %s\" % get_majority_baseline(\"serve\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier for hard...\n",
      "Reading data...\n",
      " Senses: HARD2 HARD1 HARD3\n",
      "Training classifier...\n",
      "Testing classifier...\n",
      "Accuracy: 0.8178\n",
      "\n",
      "Training classifier for interest...\n",
      "Reading data...\n",
      " Senses: interest_5 interest_6 interest_1 interest_3 interest_4 interest_2\n",
      "Training classifier...\n",
      "Testing classifier...\n",
      "Accuracy: 0.5549\n",
      "\n",
      "Training classifier for serve...\n",
      "Reading data...\n",
      " Senses: SERVE6 SERVE12 SERVE2 SERVE10\n",
      "Training classifier...\n",
      "Testing classifier...\n",
      "Accuracy: 0.4760\n",
      "\n",
      "----------------------------\n",
      "Training classifier for hard...\n",
      "Reading data...\n",
      " Senses: HARD2 HARD1 HARD3\n",
      "Training classifier...\n",
      "Testing classifier...\n",
      "Accuracy: 0.8950\n",
      "\n",
      "Training classifier for interest...\n",
      "Reading data...\n",
      " Senses: interest_5 interest_6 interest_1 interest_3 interest_4 interest_2\n",
      "Training classifier...\n",
      "Testing classifier...\n",
      "Accuracy: 0.4283\n",
      "\n",
      "Training classifier for serve...\n",
      "Reading data...\n",
      " Senses: SERVE6 SERVE12 SERVE2 SERVE10\n",
      "Training classifier...\n",
      "Testing classifier...\n",
      "Accuracy: 0.8345\n",
      "\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "target_words = \"hard interest serve\".split()\n",
    "\n",
    "for features in [wc.wsd_word_features, wc.wsd_context_features]:\n",
    "    for word in target_words:\n",
    "        print(\"Training classifier for %s...\" % word)\n",
    "        clf = wc.wsd_classifier(\n",
    "            nltk.NaiveBayesClassifier.train,\n",
    "            \"%s.pos\" % word,\n",
    "            features)\n",
    "        print()\n",
    "    print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "|Features | hard | interest | serve |\n",
    "|--|--|--|--|\n",
    "| random baseline  | 0.3333 | 0.1666 | 0.25 |\n",
    "| majority baseline  | 0.7973 | 0.5287 | 0.4143 |\n",
    "|word_features | 0.8178 |  **0.5549** | 0.4760|\n",
    "|context | **0.8950** |  0.4283 | **0.8345**|\n",
    "\n",
    "\n",
    "Why is 'interest' worse for the context features?\n",
    "\n",
    "The senses occur in very similar contexts, so the context features are not helpful. Word features seem to take a greater context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4: Semantics\n",
    "\n",
    "## 1.1) 'hard'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      " Senses: HARD2 HARD1 HARD3\n",
      "Training classifier...\n",
      "Testing classifier...\n",
      "Accuracy: 0.8950\n",
      "Writing errors to errors.txt\n",
      "      |   H   H   H |\n",
      "      |   A   A   A |\n",
      "      |   R   R   R |\n",
      "      |   D   D   D |\n",
      "      |   1   2   3 |\n",
      "------+-------------+\n",
      "HARD1 |<643> 39  20 |\n",
      "HARD2 |   6 <73>  9 |\n",
      "HARD3 |   5  12 <60>|\n",
      "------+-------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_words = \"hard interest serve\".split()\n",
    "\n",
    "word = \"hard\"\n",
    "clf = wc.wsd_classifier(\n",
    "    nltk.NaiveBayesClassifier.train,\n",
    "    \"%s.pos\" % word,\n",
    "    wc.wsd_context_features,\n",
    "    confusion_matrix=True,\n",
    "    log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91595, 0.05556, 0.02849]\n",
      "[0.06818, 0.82955, 0.10227]\n",
      "[0.06494, 0.15584, 0.77922]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "m = [\n",
    "        [643, 39, 20],\n",
    "        [  6, 73,  9],\n",
    "        [  5, 12, 60]\n",
    "]\n",
    "\n",
    "m_r = [[float(\"%8.5f\" % (x/sum(line))) for x in line] for line in m]\n",
    "print(\"\\n\".join([str(l) for l in m_r]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most difficult: HARD3 is confused by HARD2\n",
    "\n",
    "Sense for HARD3:\n",
    "`resisting weight or pressure: “a hard rock”`\n",
    "\n",
    "Sense for HARD2:\n",
    "`dispassionate “a hard bargainer”`\n",
    "\n",
    "### Examples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
